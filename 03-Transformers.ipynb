{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181752d6-cd2e-4b63-bb99-73aeb986634a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c3a734-4edd-46ef-94bf-0bc421bddc26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hack to get repo path on remotes\n",
    "import os\n",
    "REPOPATH = os.path.abspath('.')\n",
    "if \"MLX_USER\" in os.environ:\n",
    "    REPOPATH = os.path.join(\"/mlx/users\", os.environ[\"MLX_USER\"], \"repo/LLM-Tutorials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd3a712-8a9b-4845-8f07-5d74e0609e70",
   "metadata": {
    "id": "abd3a712-8a9b-4845-8f07-5d74e0609e70",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10adb3b-1e21-40d8-a0c5-4ff0862714fd",
   "metadata": {
    "id": "e10adb3b-1e21-40d8-a0c5-4ff0862714fd"
   },
   "source": [
    "# Session 3 – Transformers and Model Architectures\n",
    "\n",
    "> The emergence of Transformers dramatically changed the NLP landscape. While RNNs and LSTMs are still valuable for certain scenarios, Transformers excel in most tasks due to their powerful self-attention mechanism and ability to scale to massive datasets. Mastering both architectures gives you a well-rounded understanding of modern NLP.\n",
    "\n",
    "In the previous sessions, we explored **RNNs and LSTMs**, which have been foundational for sequential tasks. Now, we transition to **Transformers**—the architecture that has revolutionized NLP in recent years.\n",
    "\n",
    "**Session Description**:  \n",
    "This session covers the **fundamental concepts** behind Transformer architectures, including **self-attention**, **encoders/decoders**, and **their advantages over RNNs**. We’ll also look at **positional encodings**, and differences among **encoder-based (BERT)**, **decoder-based (GPT)**, and **sequence-to-sequence models (T5)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6c36b-d697-4bf4-a559-ab1032b1aca4",
   "metadata": {
    "id": "11e6c36b-d697-4bf4-a559-ab1032b1aca4"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction: Why Move Beyond RNNs?](#introduction)\n",
    "1. [Transformer Basics](#transformer-basics)\n",
    "   - [Self-Attention](#self-attention)\n",
    "   - [Multi-Head Attention](#multi-head-attention)\n",
    "   - [Positional Encoding](#positional-encoding)\n",
    "1. [High-Level Transformer Architecture](#transformer-architecture)\n",
    "   - [Encoder, Decoder, & Seq2Seq](#encoder-decoder-seq2seq)\n",
    "   - [Example: BERT vs. GPT vs. T5](#bert-gpt-t5)\n",
    "1. [Minimal Transformer Implementation in PyTorch](#minimal-transformer)\n",
    "   - [Positional Encoding from Scratch](#pos-enc-scratch)\n",
    "   - [Building a Simple Transformer Block](#simple-transformer-block)\n",
    "   - [Visualizing Attention Weights](#visualizing-attention)\n",
    "1. [(Optional) Brief Notes on Data Preprocessing](#brief-preprocessing)\n",
    "1. [(Optional) Training a Transformer](#training-transformer)\n",
    "1. [Conclusion](#conclusion)\n",
    "\n",
    "Each major concept includes an **Exercise** to help reinforce your understanding. Let’s dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d935f30-bd9c-44ab-9ef1-9daf0cde15c2",
   "metadata": {
    "id": "9d935f30-bd9c-44ab-9ef1-9daf0cde15c2"
   },
   "source": [
    "\n",
    "## <a id=\"introduction\"></a>1. Introduction: Why Move Beyond RNNs?\n",
    "\n",
    "**RNNs** (and their variants, LSTMs, GRUs) were once the state-of-the-art for many NLP tasks. However, they come with **limitations**:\n",
    "\n",
    "1. **Sequential Computation**: RNNs process tokens one by one, which can be slow for long sequences.  \n",
    "2. **Long-Term Dependencies**: Even with gating (LSTMs, GRUs), very long sequences can still cause issues (vanishing gradients).  \n",
    "3. **Parallelization Difficulty**: Because each step depends on the previous hidden state, parallelizing training or inference is more challenging.\n",
    "\n",
    "**Transformers** address these issues by using **attention mechanisms**—particularly **self-attention**—to process tokens in **parallel** and model long-range dependencies more effectively.\n",
    "\n",
    "### Exercise 1: Recap RNN Limitations\n",
    "**Goal**:  \n",
    "Write a short paragraph summarizing the main challenges you faced (or foresee) when using RNNs for large, complex sequences. How might a parallelizable architecture help?\n",
    "*(No code needed—just a conceptual reflection.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d1576-773a-4673-bdbd-edb13d1878cd",
   "metadata": {
    "id": "6f3d1576-773a-4673-bdbd-edb13d1878cd"
   },
   "source": [
    "## <a id=\"transformer-basics\"></a>2. Transformer Basics\n",
    "\n",
    "The **Transformer** architecture, introduced in the paper “Attention Is All You Need” (Vaswani et al., 2017), replaces recurrence with **self-attention** as its core building block.\n",
    "\n",
    "### <a id=\"self-attention\"></a>Self-Attention\n",
    "\n",
    "**Key Idea**: Each token in the input attends to every other token, learning contextual relationships without sequential operations.\n",
    "\n",
    "1. **Queries (Q)**, **Keys (K)**, and **Values (V)** are computed from each input token.  \n",
    "2. The **attention score** for a given token is the similarity (e.g., dot product) between its **query** and other tokens’ **keys**.  \n",
    "3. Weighted sums of **values** produce the self-attended representation.\n",
    "\n",
    "Formally, one head of attention is:\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ba4aa-c1d7-4105-a36f-43d82bf18689",
   "metadata": {
    "id": "f73ba4aa-c1d7-4105-a36f-43d82bf18689"
   },
   "source": [
    "### <a id=\"multi-head-attention\"></a>Multi-Head Attention\n",
    "\n",
    "Instead of using a single attention function, **multi-head attention** runs several in parallel:\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O\n",
    "$$\n",
    "Each head captures different aspects of pairwise relationships (e.g., syntactic vs. semantic dependencies).\n",
    "\n",
    "\n",
    "$y_t = f(h_t)$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "x_1, x_2, x_3  => \\text{Relative Position is not preserved}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad792af6-cb87-4902-8af0-6ca19c5348df",
   "metadata": {
    "id": "ad792af6-cb87-4902-8af0-6ca19c5348df"
   },
   "source": [
    "### <a id=\"positional-encoding\"></a>Positional Encoding\n",
    "\n",
    "Because self-attention does **not** inherently encode sequence order (unlike RNNs), Transformers use **positional encodings** to inject sequence position information. A common approach is **sinusoidal encoding**:\n",
    "$$\n",
    "PE_{(pos,2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right), \\quad\n",
    "PE_{(pos,2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n",
    "$$\n",
    "This allows the model to learn both relative and absolute positions in the sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7ddbb-5236-4427-810f-35dabe4eb63b",
   "metadata": {
    "id": "f0e7ddbb-5236-4427-810f-35dabe4eb63b"
   },
   "source": [
    "### Exercise 2: Calculate Self-Attention by Hand\n",
    "**Goal**:  \n",
    "1. Take a small sequence of 3 tokens with embedding size 2. Create random Q, K, V (e.g., by hand or with small random numbers).  \n",
    "2. Manually compute the attention scores and output.  \n",
    "3. Compare with a PyTorch snippet that does the same operation.  \n",
    "\n",
    "*(Focus on the concept—this is to solidify how queries, keys, and values interact.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "s_y4LzomtSe_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_y4LzomtSe_",
    "outputId": "5c73423a-78c0-431f-bcd2-dd45c10cde46",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      " [[3.53553391 2.82842712 1.41421356]\n",
      " [2.82842712 3.53553391 0.70710678]\n",
      " [1.41421356 0.70710678 0.70710678]]\n",
      "Attention Weights (softmax):\n",
      " [[0.61998512 0.30569525 0.07431963]\n",
      " [0.3176632  0.64425749 0.03807932]\n",
      " [0.50348984 0.24825508 0.24825508]]\n",
      "Output (final):\n",
      " [[1.23137562 1.61998512]\n",
      " [1.60617817 1.3176632 ]\n",
      " [1.         1.50348984]]\n"
     ]
    }
   ],
   "source": [
    "# Custom\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Token embeddings (batch_size=1, seq_len=3, embedding_size=2)\n",
    "x = np.array([\n",
    "    [1, 2],  # x1\n",
    "    [2, 1],  # x2\n",
    "    [0, 1]   # x3\n",
    "], dtype=float)\n",
    "d_k = 2\n",
    "\n",
    "# For simplicity, Q = K = V = x\n",
    "Q = x\n",
    "K = x\n",
    "V = x\n",
    "\n",
    "# 1) Compute raw scores = Q * K^T\n",
    "# shape: (3,3)\n",
    "scores = np.matmul(Q, K.T) / np.sqrt(d_k)\n",
    "\n",
    "# 2) Softmax over last axis\n",
    "from math import exp\n",
    "def softmax(vec):\n",
    "    exps = [exp(v) for v in vec]\n",
    "    s = sum(exps)\n",
    "    return [e/s for e in exps]\n",
    "\n",
    "# For each row in scores, we apply softmax\n",
    "attn = np.array([softmax(row) for row in scores])\n",
    "\n",
    "# 3) Weighted sum with V\n",
    "out = np.matmul(attn, V)\n",
    "\n",
    "print(\"Scores:\\n\", scores)\n",
    "print(\"Attention Weights (softmax):\\n\", attn)\n",
    "print(\"Output (final):\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gLw8U5xItgfP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLw8U5xItgfP",
    "outputId": "b9eb9041-055c-441b-adef-578fea136c78",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_torch: tensor([[3.5355, 2.8284, 1.4142],\n",
      "        [2.8284, 3.5355, 0.7071],\n",
      "        [1.4142, 0.7071, 0.7071]], dtype=torch.float64)\n",
      "attn_torch: tensor([[0.6200, 0.3057, 0.0743],\n",
      "        [0.3177, 0.6443, 0.0381],\n",
      "        [0.5035, 0.2483, 0.2483]], dtype=torch.float64)\n",
      "out_torch: tensor([[1.2314, 1.6200],\n",
      "        [1.6062, 1.3177],\n",
      "        [1.0000, 1.5035]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "x_torch = torch.tensor(x)  # shape (3,2)\n",
    "# Q=K=V => shape (3,2)\n",
    "\n",
    "scores_torch = (x_torch @ x_torch.T) / torch.sqrt(torch.tensor(d_k, dtype=torch.float))\n",
    "attn_torch = F.softmax(scores_torch, dim=-1)\n",
    "out_torch = attn_torch @ x_torch\n",
    "\n",
    "print(\"scores_torch:\", scores_torch)\n",
    "print(\"attn_torch:\", attn_torch)\n",
    "print(\"out_torch:\", out_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5547ff-9af0-45e6-9fbe-655da8cfeafb",
   "metadata": {
    "id": "df5547ff-9af0-45e6-9fbe-655da8cfeafb"
   },
   "source": [
    "## <a id=\"transformer-architecture\"></a>3. High-Level Transformer Architecture\n",
    "\n",
    "A typical **Transformer** stack includes:\n",
    "1. **Embedding** + **Positional Encoding** (for each token in the input).\n",
    "2. **Encoder**: multiple layers of multi-head self-attention + feedforward sub-layers.\n",
    "3. **Decoder**: similarly stacked, but it attends to the encoder’s outputs in addition to self-attending to its own inputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da24d38-cb7c-434b-9935-5606de72d975",
   "metadata": {
    "id": "1da24d38-cb7c-434b-9935-5606de72d975"
   },
   "source": [
    "### <a id=\"encoder-decoder-seq2seq\"></a>Encoder, Decoder, & Seq2Seq\n",
    "\n",
    "- **Encoder-only** (like **BERT**): Great for classification, sentence embedding, etc.  \n",
    "- **Decoder-only** (like **GPT**): Autoregressive generation, next-token prediction.  \n",
    "- **Encoder-Decoder** (like **T5**, **BART**): Sequence-to-sequence tasks (translation, summarization).\n",
    "\n",
    "**Why is this powerful?**  \n",
    "- The entire sequence can be processed in **parallel** within each attention block.  \n",
    "- Long-distance dependencies can be learned more easily via attention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b1377-9a4f-45b9-b4d4-cf1fbdb6bec0",
   "metadata": {
    "id": "4d8b1377-9a4f-45b9-b4d4-cf1fbdb6bec0"
   },
   "source": [
    "### <a id=\"bert-gpt-t5\"></a>Example: BERT vs. GPT vs. T5\n",
    "\n",
    "1. **BERT (Encoder-based)**:\n",
    "   - Uses **masked language modeling** and **next-sentence prediction** pretraining tasks.\n",
    "   - Great for classification or token-level tasks (NER, QA).\n",
    "2. **GPT (Decoder-based)**:\n",
    "   - Uses **causal (autoregressive) attention** to predict next token.\n",
    "   - Great for text generation.\n",
    "3. **T5 (Encoder-Decoder)**:\n",
    "   - “Text-to-text” framework: everything is cast as a text input → text output problem (translation, summarization, etc.).\n",
    "   - The encoder reads the input, the decoder generates the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e433c-4037-4370-a033-5dea8f72cbe7",
   "metadata": {
    "id": "065e433c-4037-4370-a033-5dea8f72cbe7"
   },
   "source": [
    "### Exercise 3: Compare Model Families\n",
    "**Goal**:  \n",
    "- Write 1–2 paragraphs explaining a real-world use case for each model class (encoder-only, decoder-only, seq2seq).  \n",
    "- Which tasks do you think an encoder-decoder would excel at, and why?\n",
    "\n",
    "\n",
    "**Possible Answer**\n",
    "\n",
    "1. Encoder-only (BERT-like)\n",
    "\n",
    "    * Use Case: Ideal for tasks that require comprehensive understanding of the input, such as classification (sentiment analysis, topic classification) or token-level tasks (named entity recognition, part-of-speech tagging). The entire input sequence is encoded into contextualized embeddings, which can then be used for classification or other discriminative tasks.\n",
    "\n",
    "2. Decoder-only (GPT-like)\n",
    "\n",
    "    * Use Case: Suited for generative tasks where we produce output tokens one at a time in an autoregressive fashion—like text completion, story generation, or code generation. The model predicts the next token based on previous tokens, making it natural for unidirectional generation.\n",
    "\n",
    "3. Encoder-Decoder (T5, BART)\n",
    "\n",
    "    * Use Case: Best for sequence-to-sequence tasks such as translation, summarization, or question answering where you read an entire input (encoder) and then generate a transformed output (decoder). The encoder provides a context-rich representation, and the decoder attends to that representation while generating the output step by step.\n",
    "\n",
    "\n",
    "_Why is encoder-decoder great for tasks like translation?_\n",
    "\n",
    "Because the encoder can deeply analyze the source sentence in its entirety, while the decoder focuses on generating the target sentence one token at a time, leveraging the encoder's representation for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f345164-2311-4b34-a0d8-0c3d28790277",
   "metadata": {
    "id": "7f345164-2311-4b34-a0d8-0c3d28790277"
   },
   "source": [
    "## <a id=\"minimal-transformer\"></a>4. Minimal Transformer Implementation in PyTorch\n",
    "\n",
    "Let’s build **from scratch** a simple Transformer block. We won’t train a full large model here, but we’ll cover essential code for:\n",
    "\n",
    "1. **Positional Encoding**  \n",
    "2. **Multi-Head Self-Attention**  \n",
    "3. **Feed-Forward Network (FFN)**  \n",
    "4. **Putting it together**  \n",
    "\n",
    "*(Note: PyTorch also provides `nn.Transformer` and related layers, but it’s instructive to implement a simplified version for clarity.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052645b-d7f8-4c6f-9933-5e6227362d1d",
   "metadata": {
    "id": "b052645b-d7f8-4c6f-9933-5e6227362d1d"
   },
   "source": [
    "### <a id=\"pos-enc-scratch\"></a>Positional Encoding from Scratch\n",
    "\n",
    "**Explanation**:\n",
    "- We generate a big matrix for positions up to `max_len`.\n",
    "- We use `sin` and `cos` on even/odd indices to encode position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a83cc2a-72b8-4edc-8fe0-3e4374f4fc96",
   "metadata": {
    "id": "2a83cc2a-72b8-4edc-8fe0-3e4374f4fc96",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        # Create a matrix of shape (max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # shape => (1, max_len, d_model) so we can broadcast\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        # add in positional encoding\n",
    "        x = x + self.pe[:, :seq_len, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280278f-7d4f-4183-aac3-fbca22bd22d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "f280278f-7d4f-4183-aac3-fbca22bd22d3",
    "outputId": "7d289c44-b3d6-4402-f71b-cb0828657453",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "d_model = 128\n",
    "max_len = 128\n",
    "annot = False\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(15, 15))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "\n",
    "pe = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
    "x = torch.zeros(1, max_len, d_model)\n",
    "pos = pe(x)[0].numpy()  # (seq_len, d_model)\n",
    "\n",
    "# sns.heatmap(pos, annot=False, cbar=False, square=True)\n",
    "# plt.gca().axis(\"off\")\n",
    "\n",
    "sns.heatmap(pos, annot=False, cbar=False, square=True, ax=ax[0])\n",
    "sns.heatmap(np.hstack([pos[:, ::2], pos[:, 1::2]]), annot=annot, fmt=r\".3f\", cbar=False, square=True, ax=ax[1])\n",
    "\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0aa63-dbf7-4ec1-9934-c39070cb418f",
   "metadata": {
    "id": "a6f0aa63-dbf7-4ec1-9934-c39070cb418f"
   },
   "source": [
    "### <a id=\"simple-transformer-block\"></a>Building a Simple Transformer Block\n",
    "\n",
    "**Notes**:  \n",
    "- The `mask` argument can be used for causal masking in a decoder or padding masking in an encoder.  \n",
    "- We apply **residual connections** and **layer normalization** after each sublayer, as in the original Transformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2a6328-eb0d-4d45-bb87-0f8ed4ac38d0",
   "metadata": {
    "id": "5d2a6328-eb0d-4d45-bb87-0f8ed4ac38d0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.linear_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        B, T, _ = x.size()\n",
    "\n",
    "        Q = self.linear_q(x).view(B, T, self.num_heads, self.d_k)\n",
    "        K = self.linear_k(x).view(B, T, self.num_heads, self.d_k)\n",
    "        V = self.linear_v(x).view(B, T, self.num_heads, self.d_k)\n",
    "\n",
    "        # permute => (batch_size, num_heads, seq_len, d_k)\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(attn, V)  # shape => (batch_size, num_heads, seq_len, d_k)\n",
    "\n",
    "        # reshape back\n",
    "        out = out.permute(0, 2, 1, 3).contiguous()\n",
    "        out = out.view(B, T, self.d_model)\n",
    "        out = self.linear_out(out)\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # 1) Self-attention + residual\n",
    "        # x = self.norm1(x)  # Pre-Norm\n",
    "        attn_out = self.attn(x, mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)  # Post-Norm\n",
    "        \n",
    "        # x = self.norm2(x)  # Pre-Norm\n",
    "        # 2) Feed-forward + residual\n",
    "        ff_out = self.ff(x)\n",
    "        x = x + self.dropout(ff_out)\n",
    "        x = self.norm2(x)  # Post-Norm\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3d18a-91f6-4c09-9790-b6cacbed9ec4",
   "metadata": {
    "id": "dcb3d18a-91f6-4c09-9790-b6cacbed9ec4"
   },
   "source": [
    "### Putting It All Together in a Minimal Encoder\n",
    "\n",
    "This is a *very* simplified version of an **encoder**. A **decoder** would also incorporate a second attention block that attends to the encoder output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1f564b-69e7-414a-b7f1-4e98655c6bc8",
   "metadata": {
    "id": "8a1f564b-69e7-414a-b7f1-4e98655c6bc8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleTransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, num_heads=4, num_layers=2, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        embedded = self.embedding(x)   # => (batch_size, seq_len, d_model)\n",
    "        embedded = self.pos_encoding(embedded)\n",
    "\n",
    "        out = embedded\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e9c56c-fc29-453c-8fd9-83371972ace4",
   "metadata": {
    "id": "87e9c56c-fc29-453c-8fd9-83371972ace4"
   },
   "source": [
    "\n",
    "### <a id=\"visualizing-attention\"></a>Visualizing Attention Weights\n",
    "\n",
    "To visualize attention:\n",
    "1. Modify `MultiHeadSelfAttention` to **return** the `attn` (attention weights).  \n",
    "2. Plot them using a heatmap (e.g., `matplotlib.seaborn.heatmap`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74699482-54ba-4c2a-b6fd-271259015a09",
   "metadata": {
    "id": "74699482-54ba-4c2a-b6fd-271259015a09",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick demonstration of capturing attention\n",
    "class MultiHeadSelfAttentionReturnWeights(MultiHeadSelfAttention):\n",
    "    def forward(self, x, mask=None):\n",
    "        B, T, _ = x.size()\n",
    "\n",
    "        Q = self.linear_q(x).view(B, T, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        K = self.linear_k(x).view(B, T, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        V = self.linear_v(x).view(B, T, self.num_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(attn, V)\n",
    "\n",
    "        out = out.permute(0, 2, 1, 3).contiguous().view(B, T, self.d_model)\n",
    "        out = self.linear_out(out)\n",
    "        return out, attn\n",
    "\n",
    "# Then, in your code, replace the old attention with \"ReturnWeights\" variant and visualize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e1eed6-765f-4796-9fe6-fe8ee7d52b63",
   "metadata": {
    "id": "66e1eed6-765f-4796-9fe6-fe8ee7d52b63"
   },
   "source": [
    "### Exercise 4: Simple Transformer Tests\n",
    "1. **Implement** the attention-weight-return version above.  \n",
    "2. Pass a small batch (like random token IDs) through the encoder.  \n",
    "3. Plot the attention heatmap for each head.  \n",
    "4. Observe how each head “pays attention” to different positions in the sequence.\n",
    "\n",
    "\n",
    "**Possible Answer**\n",
    "\n",
    "* Each row corresponds to how the query token attends to others.\n",
    "* Each column corresponds to a key token.\n",
    "* If certain squares have high values, that means the query token “pays attention” to that particular key token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "IyyCAnzzuJVL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "IyyCAnzzuJVL",
    "outputId": "b80b3133-e3b1-4634-b01a-05e116ee3484",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppose we have embeddings of shape (batch_size=1, seq_len=4, d_model=8)\n",
    "x_fake = torch.randn(1, 4, 8)\n",
    "attn_module = MultiHeadSelfAttentionReturnWeights(d_model=8, num_heads=2)\n",
    "output, attention_weights = attn_module(x_fake)\n",
    "\n",
    "# attention_weights shape => (1, num_heads=2, seq_len=4, seq_len=4)\n",
    "attn_head_1 = attention_weights[0, 0].detach().numpy()  # shape (4,4)\n",
    "attn_head_2 = attention_weights[0, 1].detach().numpy()  # shape (4,4)\n",
    "\n",
    "# Plot head 1\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(attn_head_1, annot=True, cmap=\"Blues\")\n",
    "plt.title(\"Attention Head 1\")\n",
    "plt.xlabel(\"Key Positions\")\n",
    "plt.ylabel(\"Query Positions\")\n",
    "plt.show()\n",
    "\n",
    "# Plot head 2\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(attn_head_2, annot=True, cmap=\"Reds\")\n",
    "plt.title(\"Attention Head 2\")\n",
    "plt.xlabel(\"Key Positions\")\n",
    "plt.ylabel(\"Query Positions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ea9e8-b512-471f-becb-9ac46c111af8",
   "metadata": {
    "id": "c74ea9e8-b512-471f-becb-9ac46c111af8"
   },
   "source": [
    "## <a id=\"brief-preprocessing\"></a>5. (Optional) Brief Notes on Data Preprocessing\n",
    "\n",
    "While the **focus** of this session is modeling, recall from previous sessions that **preprocessing** for Transformers typically involves **subword tokenization** (e.g., BPE or WordPiece), special tokens (like `[CLS]`, `[SEP]`), and attention masks for padding. Tools like **Hugging Face**’s `transformers` and `tokenizers` libraries handle these details seamlessly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea5e3d-90d1-4963-aaf9-87a68ff3718a",
   "metadata": {
    "id": "6eea5e3d-90d1-4963-aaf9-87a68ff3718a"
   },
   "source": [
    "## <a id=\"training-transformer\"/>6. (Optional) Training a Simple Transformer Decoder for Causal Language Modeling\n",
    "\n",
    "In this optional section, we’ll demonstrate how to train a **Transformer Decoder** in a **causal language modeling** setup (like GPT). We’ll use a **tiny Shakespeare** dataset to keep things manageable. The key ideas are:\n",
    "\n",
    "1. **Decoder-Only Architecture**: We only stack self-attention blocks, no separate encoder.  \n",
    "2. **Causal Mask (Triangular Mask)**: Ensures each token only attends to itself and previous tokens, not future ones.  \n",
    "3. **Next-Token Prediction**: At each time step, predict the *next* character (or token).\n",
    "\n",
    "Below is a step-by-step guide and a minimal code outline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b50364-aba4-48af-b0db-daa1a8203c85",
   "metadata": {
    "id": "86b50364-aba4-48af-b0db-daa1a8203c85"
   },
   "source": [
    "### A. Preparing a Tiny Shakespeare Dataset\n",
    "\n",
    "For demonstration, assume you have a file named `tiny_shakespeare.txt` (you can get a version from [Andrej Karpathy’s repo](https://github.com/karpathy/char-rnn) or anywhere else). Let’s read it in and do a simple **character-level** approach:\n",
    "\n",
    "\n",
    "**Note**: For a more advanced approach, you could use subword tokenization. But character-level is straightforward for a small dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Zkb3WTL40W6o",
   "metadata": {
    "id": "Zkb3WTL40W6o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O tiny_shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47d30fd-d5ca-486f-9195-c95b00a394f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "a47d30fd-d5ca-486f-9195-c95b00a394f5",
    "outputId": "6e5fd224-3f52-4076-f403-85dddc4d7378",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 1115394\n",
      "Vocabulary size: 65\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "\n",
    "# 1) Load a small Shakespeare corpus\n",
    "with open(\"tiny_shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "# 2) Build a character-level vocab\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Convert text to indices\n",
    "data = [char2idx[ch] for ch in text]\n",
    "data_tensor = torch.tensor(data, dtype=torch.long)\n",
    "\n",
    "# Let's define some hyperparameters\n",
    "seq_length = 64  # chunk size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f447a55-60a7-424c-a082-372e27bbc403",
   "metadata": {
    "id": "0f447a55-60a7-424c-a082-372e27bbc403"
   },
   "source": [
    "\n",
    "### B. Creating a Causal LM Dataset\n",
    "\n",
    "We want each sequence to predict the *next* character for each position. So if our sequence is $[x_0, x_1, ..., x_{t}]$, we want to predict $[x_1, x_2, ..., x_{t+1}]$. We can store them as `(input_seq, target_seq)` pairs.\n",
    "\n",
    "Here, `x_seq[i]` should predict `y_seq[i]`, shifting by one character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e20e759-cff9-475f-957e-34f522441003",
   "metadata": {
    "id": "8e20e759-cff9-475f-957e-34f522441003",
    "outputId": "e0658747-4303-43de-bdaf-5af3e746cad4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num batches: 544\n"
     ]
    }
   ],
   "source": [
    "class ShakespeareCharDataset(Dataset):\n",
    "    def __init__(self, data_tensor, seq_length=64):\n",
    "        self.data = data_tensor\n",
    "        self.seq_length = seq_length\n",
    "        # We'll create as many full chunks as possible\n",
    "        self.num_samples = len(self.data) // seq_length - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_length\n",
    "        x_seq = self.data[start : start + self.seq_length]\n",
    "        y_seq = self.data[start + 1 : start + self.seq_length + 1]\n",
    "        return x_seq, y_seq\n",
    "\n",
    "dataset = ShakespeareCharDataset(data_tensor, seq_length=seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "print(\"Num batches:\", len(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3fc2d-fc36-4623-80e1-c2766e235088",
   "metadata": {
    "id": "54c3fc2d-fc36-4623-80e1-c2766e235088"
   },
   "source": [
    "\n",
    "### C. Building a Causal Decoder Model\n",
    "\n",
    "We’ll adapt our **TransformerBlock** for a **decoder-only** scenario. The main difference is applying a **causal mask** so tokens cannot attend to future positions.\n",
    "\n",
    "#### 1. Causal Mask Function\n",
    "\n",
    "A common technique is to create a **triangular** attention mask of shape `(seq_length, seq_length)` where positions `j > i` are masked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01cf5175-ea7c-4f89-af0c-ac3eb20ee7a3",
   "metadata": {
    "id": "01cf5175-ea7c-4f89-af0c-ac3eb20ee7a3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_causal_mask(seq_length):\n",
    "    \"\"\"\n",
    "    Returns a (seq_length, seq_length) mask,\n",
    "    where positions j>i are set to False (meaning \"do not attend\").\n",
    "    \"\"\"\n",
    "    # shape (seq_length, seq_length)\n",
    "    mask = torch.tril(torch.ones(seq_length, seq_length)).bool()\n",
    "    return mask  # True means \"allowed to attend\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b390a-92dd-4215-840d-4cc7eec561e3",
   "metadata": {
    "id": "7f0b390a-92dd-4215-840d-4cc7eec561e3"
   },
   "source": [
    "\n",
    "#### 2. Simple DecoderBlock\n",
    "\n",
    "We can reuse a similar block to our earlier `TransformerBlock`, but we’ll clarify the self-attention is **causal**.\n",
    "\n",
    "*(We’re assuming the `MultiHeadSelfAttention` class from the prior session or snippet, which can apply `mask` to the `scores`.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60614eb3-d3c6-4c57-aed6-0f419b5d741b",
   "metadata": {
    "id": "60614eb3-d3c6-4c57-aed6-0f419b5d741b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # 1) Causal self-attention + residual\n",
    "        attn_out = self.attn(x, mask=mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # 2) Feed-forward + residual\n",
    "        ff_out = self.ff(x)\n",
    "        x = x + self.dropout(ff_out)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b9198-f14f-42f8-8d5a-01dba20c9ac5",
   "metadata": {
    "id": "a74b9198-f14f-42f8-8d5a-01dba20c9ac5"
   },
   "source": [
    "\n",
    "#### 3. Decoder Model\n",
    "\n",
    "We can define a small model that:\n",
    "1. Embeds characters,\n",
    "2. Adds positional encoding,\n",
    "3. Stacks `DecoderBlock` layers,\n",
    "4. Outputs logits over the vocabulary at each time step.\n",
    "\n",
    "Note how we generate the `causal_mask(T,T)` and pass it along so each token can’t attend to future positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf3f6223-fed9-476b-ae78-db78c154b7f4",
   "metadata": {
    "id": "cf3f6223-fed9-476b-ae78-db78c154b7f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CausalTransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, num_heads=4, num_layers=2, max_len=512):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_length) of token indices\n",
    "        returns: (batch_size, seq_length, vocab_size)\n",
    "        \"\"\"\n",
    "        B, T = x.size()\n",
    "        # Embeddings + positions\n",
    "        embed = self.embedding(x)  # (B, T, d_model)\n",
    "        embed = self.pos_encoding(embed)  # add positional info\n",
    "\n",
    "        # Generate causal mask (for each batch, we broadcast the same mask)\n",
    "        mask = generate_causal_mask(T).to(x.device)  # (T, T)\n",
    "\n",
    "        out = embed\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, mask=mask)\n",
    "\n",
    "        # Predict next char at each position\n",
    "        logits = self.fc_out(out)  # (B, T, vocab_size)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325cea6-4e6a-40f6-8466-b391ca258715",
   "metadata": {
    "id": "7325cea6-4e6a-40f6-8466-b391ca258715"
   },
   "source": [
    "\n",
    "### D. Training Loop\n",
    "\n",
    "We’ll do **cross-entropy** on each position’s next-char prediction.\n",
    "\n",
    "For a small dataset (like `tiny_shakespeare.txt`), you might want more epochs or a smaller `d_model`. The final model can then do **character-level generation** using a standard autoregressive approach:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2527c62-f80b-4be3-bd3e-a38fb570e0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = CausalTransformerDecoder(vocab_size, d_model=512, num_heads=4, num_layers=3)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddcbb0b3-0726-4ffb-b0ab-113fc0a203b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 9,523,777\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for param in model.parameters():\n",
    "    total_params += param.numel()\n",
    "\n",
    "print(f\"Number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fe2517f-8b1c-4031-bf6a-699f3e63c9b4",
   "metadata": {
    "id": "6fe2517f-8b1c-4031-bf6a-699f3e63c9b4",
    "outputId": "bf05d6d6-24b5-4e68-d17f-9f930ad32c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 2.1153\n",
      "CPU times: user 1h 40min 29s, sys: 3min 12s, total: 1h 43min 41s\n",
      "Wall time: 13min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x_seq, y_seq in dataloader:\n",
    "        x_seq, y_seq = x_seq.to(device), y_seq.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # logits: (batch_size, seq_length, vocab_size)\n",
    "        logits = model(x_seq)\n",
    "\n",
    "        # reshape for cross-entropy\n",
    "        # we want (batch_size*seq_length, vocab_size) vs. (batch_size*seq_length)\n",
    "        logits_reshaped = logits.view(-1, vocab_size)\n",
    "        targets_reshaped = y_seq.view(-1)\n",
    "\n",
    "        loss = criterion(logits_reshaped, targets_reshaped)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ff4fe-6fdb-44d4-b63f-59549a4b1ff9",
   "metadata": {
    "id": "cc0ff4fe-6fdb-44d4-b63f-59549a4b1ff9"
   },
   "source": [
    "\n",
    "### E. Generating Shakespeare-Like Text\n",
    "\n",
    "After training, you can generate text:\n",
    "\n",
    "**Notes**:\n",
    "- Adjust `temperature` for more or less randomness.\n",
    "- If the dataset is tiny, results may still be partially gibberish. You can experiment with more epochs or a bigger model dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98a64d5-8e6c-4eb4-9274-95a45c010156",
   "metadata": {
    "id": "c98a64d5-8e6c-4eb4-9274-95a45c010156",
    "outputId": "8acc4566-a7d8-4aea-a4ef-fb3227b67362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      " ROMEO:\n",
      "I'll it; how, he'st the speak'st lockle comble.\n",
      "\n",
      "KING EDWARRRS LLL\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WICH:\n",
      "WAR, L L ch RS V L M V HARUS LL LLLO:\n",
      "LLLLO:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "O:\n",
      "ARG L loulouliloulorongeloulaloulouloune'lon R L LO:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "S F laroulixele'land LLLLO:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IC V O:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PRS V:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Y lorelin LARG O\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_text(model, start_str=\"ROMEO:\", max_new_tokens=200, temperature=1.0):\n",
    "    model.eval()\n",
    "    # Convert start_str to indices\n",
    "    input_ids = torch.tensor([char2idx[ch] for ch in start_str], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # We'll generate token by token\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Get logits for the last token\n",
    "        logits = model(input_ids)  # shape: (1, seq_len, vocab_size)\n",
    "        logits = logits[:, -1, :]  # only the last time step\n",
    "        logits = logits / temperature\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, 1).item()\n",
    "\n",
    "        # Append to sequence\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "\n",
    "    # Convert back to characters\n",
    "    generated_seq = [idx2char[t.item()] for t in input_ids[0]]\n",
    "    return \"\".join(generated_seq)\n",
    "\n",
    "sample_output = generate_text(model, start_str=\"ROMEO:\", max_new_tokens=300, temperature=0.8)\n",
    "print(\"Generated:\\n\", sample_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ebe01-4eaa-4978-8a73-6ce9b35c9b7f",
   "metadata": {
    "id": "d03ebe01-4eaa-4978-8a73-6ce9b35c9b7f"
   },
   "source": [
    "\n",
    "### Summary of This Optional Section\n",
    "\n",
    "- We showed a **decoder-only Transformer** for **causal language modeling**.\n",
    "- We used a **triangular mask** to prevent each token from attending to future positions.\n",
    "- We trained it on a **tiny Shakespeare** dataset with a **character-level** approach.\n",
    "\n",
    "**Advantages**:\n",
    "- This approach is the conceptual basis for **GPT-like** models (decoder-based Transformers).\n",
    "- You can scale up the same logic for bigger datasets and more layers.\n",
    "\n",
    "Feel free to explore:\n",
    "- **Subword tokenization** for improved text quality.  \n",
    "- **More layers** or bigger hidden dimensions.  \n",
    "- **Longer training** if you have the resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84453e1-b366-4bda-828c-3ebc608a945e",
   "metadata": {
    "id": "f84453e1-b366-4bda-828c-3ebc608a945e"
   },
   "source": [
    "## <a id=\"conclusion\"></a>7. Conclusion\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. **Self-Attention** provides a parallelizable mechanism that can handle **long-distance dependencies** better than RNNs.  \n",
    "2. **Multi-Head** setups capture different relational aspects simultaneously.  \n",
    "3. **Positional Encodings** introduce sequence order into an otherwise order-agnostic attention mechanism.  \n",
    "4. Transformers come in **encoder-only** (BERT), **decoder-only** (GPT), and **encoder-decoder** (T5) variants, each suited for different tasks.\n",
    "\n",
    "With the knowledge from **Session 2 (RNNs)** and **Session 3 (Transformers)**, you’re now well-equipped to:\n",
    "- **Implement** or **fine-tune** these models.\n",
    "- **Explore** how attention reveals interpretability.\n",
    "- **Optimize** training for large-scale tasks (though we didn’t dive deeply into that here).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670d47a-a20c-4ba1-a4a4-c9128603669a",
   "metadata": {
    "id": "5670d47a-a20c-4ba1-a4a4-c9128603669a"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b51f59-0c0f-413e-a0a2-f825312d9b5d",
   "metadata": {
    "id": "e0b51f59-0c0f-413e-a0a2-f825312d9b5d"
   },
   "source": [
    "# Fun: Train a ~Shakespearean~ CN Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "966d30e8-4c58-4d9e-9b72-66b0b95d36c8",
   "metadata": {
    "id": "966d30e8-4c58-4d9e-9b72-66b0b95d36c8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "DATA_PATH = os.path.join(REPOPATH, \"cnbook\")\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "BASE_URL = \"https://raw.githubusercontent.com/aboutjm/Automation/master/book/%5B三体1-3%2B三体X修订增补%5DTXT精校版.刘慈欣/\"\n",
    "filelist = [\n",
    "    \"三体1疯狂年代.txt\",\n",
    "    \"三体2黑暗森林.txt\",\n",
    "    \"三体3死神永生.txt\",\n",
    "    \"三体X修订增补版.txt\",\n",
    "]\n",
    "\n",
    "filepaths = []\n",
    "\n",
    "for idx, f in enumerate(filelist):\n",
    "    url = BASE_URL + f\n",
    "    encoded_url = urllib.parse.quote(url, safe=':/%')\n",
    "    file_path = os.path.join(DATA_PATH, f\"file{idx}.txt\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Downloading {encoded_url}...\")\n",
    "        !wget $encoded_url -O $file_path -q\n",
    "    filepaths.append(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4feace96-9dca-4d10-8701-0432f1cf3d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "texts = []\n",
    "\n",
    "for fpath in filepaths:\n",
    "    with open(fpath, \"r\", encoding=\"gbk\") as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)\n",
    "merged_text = \"\\n\\n\".join(texts)\n",
    "\n",
    "# Cleanup: Replace \\u3000 with space\n",
    "merged_text = merged_text.replace(\"\\u3000\", \" \")\n",
    "# Cleanup: Replace “ and ” with \"\n",
    "merged_text = merged_text.replace(\"“\", '\"')\n",
    "merged_text = merged_text.replace(\"”\", '\"')\n",
    "# Cleanup: Replace double blank characters with a single ones\n",
    "# merged_text = merged_text.replace(\"  \", \" \")\n",
    "merged_text = re.sub(r\"[ ]+\", \" \", merged_text)\n",
    "merged_text = re.sub(r\"[\\t]+\", \"\\t\", merged_text)\n",
    "merged_text = re.sub(r\"[\\n]+\", \"\\n\", merged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95bcaf58-e9de-49c5-917f-e06f19d60750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique chars found: 3772\n",
      "Example of characters (top): ['，', '的', '。', '\"', '一', ' ', '是', '\\n', '了', '在', '这', '不', '个', '有', '他', '人', '到', '中', '们', '我', '上', '地', '时', '来', '那', '大', '说', '着', '能', '出', '看', '和', '后', '你', '就', '面', '也', '可', '现', '没', '都', '她', '对', '但', '过', '星', '？', '下', '太', '子']\n",
      "Example of characters (bot): ['贷', '茹', '豹', '彷', '徨', '缥', '缈', '茗', '荑', '宛', '凰', '旬', '捺', '狐', '猴', '迭', '赦', '朱', '茧', '睥', '睨', '伫', '氤', '氲', '▽', '◇', '霄', '谚', '嗫', '嚅', '宸', '谕', '鸢', '踌', '躇', '匾', '炒', '隘', '齑', '酬', '敝', '帚', '诟', '佬', '吭', '琢', '裆', '怂', '恿', '@']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Create vocabulary of unique characters\n",
    "char_counts = Counter(merged_text)\n",
    "chars = sorted(char_counts.keys(), key=char_counts.get, reverse=True)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(\"Unique chars found:\", vocab_size)\n",
    "print(\"Example of characters (top):\", chars[:50])\n",
    "print(\"Example of characters (bot):\", chars[-50:])\n",
    "\n",
    "# Create mapping from character to index (and reverse)\n",
    "_char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "_idx2char = {i: ch for ch, i in _char2idx.items()}\n",
    "\n",
    "# Add special characters\n",
    "for special_token in [\"<|UNK|>\"]:\n",
    "    k = len(_char2idx)\n",
    "    _char2idx[special_token] = k\n",
    "    _idx2char[k] = special_token\n",
    "\n",
    "# Utility functions\n",
    "def char2idx(ch):\n",
    "    return [_char2idx.get(c, \"<|UNK|>\") for c in ch]\n",
    "def idx2char(idx):\n",
    "    if isinstance(idx, torch.Tensor):\n",
    "        return idx2char(idx.detach().cpu().numpy())\n",
    "    if isinstance(idx, np.ndarray):\n",
    "        return idx2char(idx.tolist())\n",
    "    if isinstance(idx, int):\n",
    "        return _idx2char.get(idx, \"<|UNK|>\")\n",
    "    return [idx2char(i) for i in idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e1f122d-421a-4475-bb1b-722021af45da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_tensor shape: torch.Size([1017810])\n"
     ]
    }
   ],
   "source": [
    "# Convert all text to indices\n",
    "data_as_indices = char2idx(merged_text)\n",
    "data_tensor = torch.tensor(data_as_indices, dtype=torch.long)\n",
    "print(\"data_tensor shape:\", data_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9919b29e-300d-4cbe-80e7-de5581ccc072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 10177\n",
      "Example X (indices): tensor([   5,   58,   54, 1777,   17,  178,  347,  688,  300,  458])\n",
      "Example Y (index): tensor([  58,   54, 1777,   17,  178,  347,  688,  300,  458, 1371])\n",
      "Example X (decoded): \" 三体（中国科幻基石\"\n",
      "Example Y (decoded): \"三体（中国科幻基石丛\"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data_tensor, seq_length):\n",
    "        self.data = data_tensor\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        # We can form this many sequences (minus 1 for the target)\n",
    "        return len(self.data) // self.seq_length - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_length\n",
    "        x_seq = self.data[start : start + self.seq_length]\n",
    "        # Targets are the subsequent seq_length characters\n",
    "        y_seq = self.data[start+1 : start + self.seq_length + 1]\n",
    "        return x_seq, y_seq\n",
    "\n",
    "seq_length = 100\n",
    "dataset = CharDataset(data_tensor, seq_length=seq_length)\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "\n",
    "# For demonstration, let's get one example\n",
    "example_x, example_y = dataset[0]\n",
    "print(\"Example X (indices):\", example_x[:10])\n",
    "print(\"Example Y (index):\", example_y[:10])\n",
    "print(f\"Example X (decoded): \\\"{''.join(idx2char(example_x[:10]))}\\\"\")\n",
    "print(f\"Example Y (decoded): \\\"{''.join(idx2char(example_y[:10]))}\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d47146d-36df-4553-8748-03b7717ea127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "\n",
    "# def batch_second(batch):\n",
    "#     x, y = list(zip(*batch))\n",
    "#     x = torch.stack(x, 1)\n",
    "#     y = torch.stack(y, 1)\n",
    "\n",
    "#     return x, y\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13163647-8f5c-4907-a47a-ffc3b511783c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CausalTransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, num_heads=4, num_layers=2, max_len=100):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_length) of token indices\n",
    "        returns: (batch_size, seq_length, vocab_size)\n",
    "        \"\"\"\n",
    "        B, T = x.size()\n",
    "        # Embeddings + positions\n",
    "        embed = self.embedding(x)  # (B, T, d_model)\n",
    "        embed = self.pos_encoding(embed)  # add positional info\n",
    "\n",
    "        # Generate causal mask (for each batch, we broadcast the same mask)\n",
    "        mask = generate_causal_mask(T).to(x.device)  # (T, T)\n",
    "\n",
    "        out = embed\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, mask=mask)\n",
    "\n",
    "        # Predict next char at each position\n",
    "        logits = self.fc_out(out)  # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "035c2f8c-0f7d-45a6-afde-2e946d1f1471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = CausalTransformerDecoder(vocab_size, d_model=512, num_heads=4, num_layers=3, max_len=100)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=5)  # Reduce learning rate by half\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b427d55-836e-404b-a2ca-cd0d90569f08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 13,323,452\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for param in model.parameters():\n",
    "    total_params += param.numel()\n",
    "\n",
    "print(f\"Number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7842b-e741-4a5b-923d-9e4d6ed42730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MODEL_SAVE_PATH = os.path.join(REPOPATH, \"models\")\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "history = []\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for x_seq, y_seq in dataloader:\n",
    "        x_seq, y_seq = x_seq.to(device), y_seq.to(device)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(x_seq)\n",
    "\n",
    "        # Reshape logits and targets for cross-entropy\n",
    "        # We want CE across all time steps\n",
    "        logits_reshaped = logits.view(-1, vocab_size)   # (batch_size*seq_length, vocab_size)\n",
    "        targets_reshaped = y_seq.view(-1)               # (batch_size*seq_length,)\n",
    "\n",
    "        loss = criterion(logits_reshaped, targets_reshaped)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    if epoch == 0 or (epoch + 1) % 10 == 0 or epoch + 1 == num_epochs:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Correct prediction: {math.exp(-avg_loss):.1%}\")\n",
    "    scheduler.step(avg_loss)\n",
    "    history.append(avg_loss)\n",
    "\n",
    "model_name = f\"checkpoint_cn_xformer.pt\"\n",
    "model_path = os.path.join(MODEL_SAVE_PATH, model_name)\n",
    "torch.save({\n",
    "    \"last_epoch\": epoch,\n",
    "    \"last_loss\": avg_loss,\n",
    "    \"history\": history,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "}, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055c08b-9ec2-4bc6-923d-557dd500f8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_text(model, start_str=\"ROMEO:\", max_new_tokens=200, temperature=1.0):\n",
    "    model.eval()\n",
    "    # Convert start_str to indices\n",
    "    # input_ids = torch.tensor([char2idx(ch) for ch in start_str], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    input_ids = torch.tensor(char2idx(start_str), dtype=torch.long).unsqueeze(0).to(device)\n",
    "    # return model(input_ids)\n",
    "    # We'll generate token by token\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Get logits for the last token\n",
    "        inp = input_ids[:, -98:]\n",
    "        logits = model(inp)  # shape: (1, seq_len, vocab_size)\n",
    "        logits = logits[:, -1, :]  # only the last time step\n",
    "        logits = logits / temperature\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, 1).item()\n",
    "\n",
    "        # Append to sequence\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "        \n",
    "\n",
    "    # Convert back to characters\n",
    "    generated_seq = [idx2char(t.item()) for t in input_ids[0]]\n",
    "    return \"\".join(generated_seq)\n",
    "\n",
    "sample_output = generate_text(model, start_str=\"ROMEO:\", max_new_tokens=300, temperature=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f95bd-6dc0-469c-b0f2-86432b6ed994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Generated:\\n\", sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad284e6-0701-41c9-a520-4334b66c0c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
